{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "NOL9zUq9C3up"
   },
   "source": [
    "# Exploring Gender Bias in Word Embeddings\n",
    "\n",
    "This lab is based on a tutorial for the responsibly Python package. You can view the original tutorial and learn more about responsibly here: [https://learn.responsibly.ai/word-embedding](https://learn.responsibly.ai/word-embedding).\n",
    "\n",
    "Please go through this notebook by running each cell and answering the questions which occur at the end of each part. Some will involve you coding while others will simply require that you write a response in markdown. The questions are marked by whales (üê≥).\n",
    "\n",
    "#### Note: You will be using a smaller version of the the full Word2Vec (which compressed is still about 2GB). You may find that some words you want to use for the assignment are not included in the smaller dictionary. You may have to find words to use by trial and error."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "idhysORlC3uy"
   },
   "source": [
    "# Part 1: Setup"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Vn-4xIh6C3uz"
   },
   "source": [
    "## 1.1 - Install and load packages"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "_nQ508U3C3uz"
   },
   "source": [
    "- On a mac, open a terminal window\n",
    "- make a conda environment with strictly less than Python 3.8 but greater than or equal to Python 3.6\n",
    "\n",
    "conda create -n py37 python=3.7 anaconda\n",
    "\n",
    "conda activate py37\n",
    "\n",
    "- **Install numpy and matplotlib (v2.2.3) through conda**\n",
    "\n",
    "conda install numpy\n",
    "\n",
    "conda install matplotlib=2.2.3\n",
    "\n",
    "pip install responsibly\n",
    "\n",
    "- On a mac you then load Jupyter Notebook by typing the command below.  The ampersand is to run the notebook in the \"background\", that is to allow you to continue typing other commands in the same terminal window.\n",
    "\n",
    "jupyter-notebook& \n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from IPython.display import Image\n",
    "import warnings\n",
    "from math import acos, degrees\n",
    "from operator import itemgetter\n",
    "from copy import deepcopy\n",
    "\n",
    "# matplotlib\n",
    "from matplotlib import pylab as plt\n",
    "import matplotlib.pylab as plt\n",
    "\n",
    "# numpy\n",
    "import numpy as np\n",
    "from numpy.testing import assert_almost_equal\n",
    "from numpy.linalg import norm\n",
    "\n",
    "# scikit-learn\n",
    "from sklearn.manifold import TSNE\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "\n",
    "# responsibly\n",
    "import responsibly\n",
    "from responsibly.we import most_similar\n",
    "from responsibly.we import GenderBiasWE\n",
    "from responsibly.we import load_w2v_small\n",
    "from responsibly.we import calc_all_weat\n",
    "from responsibly.we import calc_single_weat\n",
    "from responsibly.we import GenderBiasWE\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "rU1uolhsC3u0"
   },
   "source": [
    "## 1.2 - Validate Installation of `responsibly`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "E63RXd26C3u0"
   },
   "outputs": [],
   "source": [
    "# You should get '0.1.3'\n",
    "responsibly.__version__"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "j580hhNJC3u2"
   },
   "source": [
    "# Part 2: Motivation - Why use word embeddings?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "_jN4gKKRDgBl"
   },
   "source": [
    "## 2.1 - [NLP (Natural Language Processing)](https://en.wikipedia.org/wiki/Natural_language_processing)\n",
    "\n",
    "Partial list of tasks and applications:\n",
    "\n",
    "- Classification\n",
    "- Machine Translation\n",
    "- Information Retrieval\n",
    "- Conversation Chatbots\n",
    "- Coreference Resolution"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Image(\"./images/corefexample.png\", width=600)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "<small>Source: [Stanford Natural Language Processing Group](https://nlp.stanford.edu/projects/coref.shtml)</small>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "DyseaT6ADi5U"
   },
   "source": [
    "## 2.2 - Machine Learning (NLP) Pipeline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Image(\"./images/nlp-pipeline.png\", width=600)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "<small>Source: [Kai-Wei Chang (UCLA) - What It Takes to Control Societal Bias in Natural Language Processing](https://www.youtube.com/watch?v=RgcXD_1Cu18)</small>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "0pCZrVekC3u2"
   },
   "source": [
    "## 2.3 - How can we represent language to a machine?\n",
    "\n",
    "We need some kind of *dictionary* to transform/encode from a human representation to a machine representation (words ‚Üí numbers)\n",
    "\n",
    "### Bag of Words (for a text)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Image(\"./images/bow.png\", width=300)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<small>Source: Zheng, A.& Casari, A. (2018). Feature Engineering for Machine Learning. O'Reilly Media.</small>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "7SIe0KUQC3u2"
   },
   "outputs": [],
   "source": [
    "vocabulary = ['it', 'they', 'puppy', 'and', 'cat', 'aardvark', 'cute', 'extremely', 'not']\n",
    "\n",
    "vectorizer = CountVectorizer(vocabulary=vocabulary)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "nkDdYeLzC3u3"
   },
   "outputs": [],
   "source": [
    "sentence = 'it is a puppy and it is extremely cute'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "9euJwWBnC3u4"
   },
   "outputs": [],
   "source": [
    "vectorizer.fit_transform([sentence]).toarray()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "lPd-yhuJC3u4"
   },
   "outputs": [],
   "source": [
    "vectorizer.fit_transform(['it is not a puppy and it is extremely cute']).toarray()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "pT80g0l7C3u4"
   },
   "outputs": [],
   "source": [
    "vectorizer.fit_transform(['it is a puppy and it is extremely not cute']).toarray()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "t723YhaCC3u4"
   },
   "source": [
    "Read more about scikit-learn's text feature extraction [here](https://scikit-learn.org/stable/modules/feature_extraction.html#text-feature-extraction)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "OYLHZnIrC3u5"
   },
   "source": [
    "### One-hot representation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "Z6iVvcLzC3u5"
   },
   "outputs": [],
   "source": [
    "[vectorizer.fit_transform([word]).toarray()\n",
    " for word in sentence.split()\n",
    " if word in vocabulary]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Mptgh5VAC3u5"
   },
   "source": [
    "### A problem with one-hot representation\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Image(\"./images/audio-image-text.png\", width=600)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<small> Source: [Tensorflow Documentation](https://www.tensorflow.org/tutorials/representation/word2vec) </small>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "tAxMVpIcC3u5"
   },
   "source": [
    "### Embedding a word in a n-dimensional space\n",
    "\n",
    "Distance ~ Semantic Similarity\n",
    "\n",
    "Again, for the purposes of this assignment, these are just references and additional sources of information. You should have already seen \"The Illustrated Word2vec\" by Jay Alammar.\n",
    "\n",
    "#### Examples (algorithms and pre-trained models)\n",
    "- [Word2Vec](https://code.google.com/archive/p/word2vec/)\n",
    "- [GloVe](https://nlp.stanford.edu/projects/glove/)\n",
    "- [fastText](https://fasttext.cc/)\n",
    "- [ELMo](https://allennlp.org/elmo) (contextualized)\n",
    "\n",
    "#### Training: using *word-context* relationships from a corpus.\n",
    "\n",
    "See: [The Illustrated Word2vec by Jay Alammar](http://jalammar.github.io/illustrated-word2vec/)\n",
    "\n",
    "#### State of the Art - Contextual Word Embedding ‚Üí Language Models\n",
    "- [The Illustrated BERT, ELMo, and co. (How NLP Cracked Transfer Learning) by Jay Alammar](http://jalammar.github.io/illustrated-bert/)\n",
    "- Microsoft - [NLP Best Practices](https://github.com/microsoft/nlp-recipes)\n",
    "- [Tracking Progress in Natural Language Processing](https://nlpprogress.com/)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## üê≥ **Questions** üê≥"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- What is the difference between the bag-of-words approach and the one-hot encoding demonstrated here?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "+ Can you think of a use case where one-hot encoding or a bag of words approach would be better than a high-dimensional word embedding? If so, why? If not, why not?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "MxWD54mFC3u6"
   },
   "source": [
    "# Part 3: Playing with Word2Vec word embeddings"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "[Word2Vec](https://code.google.com/archive/p/word2vec/) - Google News - 100B tokens, 3M vocab, cased, 300d vectors - only lowercase vocab extracted\n",
    "\n",
    "Loaded using [`responsibly`](http://docs.responsibly.ai) package, the function [`responsibly.we.load_w2v_small`]() returns a [`gensim`](https://radimrehurek.com/gensim/)'s [`KeyedVectors`](https://radimrehurek.com/gensim/models/keyedvectors.html#gensim.models.keyedvectors.KeyedVectors) object."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "AZmUr2o3Dwai"
   },
   "source": [
    "## 3.1 - Basic Properties"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "VafEGudyC3u6"
   },
   "outputs": [],
   "source": [
    "# ignore warnings\n",
    "# generally, you shouldn't do that, but for this tutorial we'll do so for the sake of simplicity\n",
    "warnings.filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "_AKj8lzLC3u6"
   },
   "outputs": [],
   "source": [
    "# this loads a small version of Word2Vec which does not include the full vocabulary \n",
    "w2v_small = load_w2v_small()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "_5SjqSjtC3u6"
   },
   "outputs": [],
   "source": [
    "# vocabulary size\n",
    "len(w2v_small.vocab)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "-vYyVOfnC3u7"
   },
   "outputs": [],
   "source": [
    "# get the vector of the word \"home\"\n",
    "print('home =', w2v_small['home'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "WCuUyFuIC3u7"
   },
   "outputs": [],
   "source": [
    "# the word embedding dimension, in this case, is 300\n",
    "\n",
    "len(w2v_small['home'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "ADMLat0gC3u7"
   },
   "outputs": [],
   "source": [
    "# all the words are normalized (=have norm equal to one as vectors)\n",
    "\n",
    "norm(w2v_small['home'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "an6l7AKwC3u7"
   },
   "outputs": [],
   "source": [
    "# make sure that all the vectors are normalized!\n",
    "\n",
    "length_vectors = norm(w2v_small.vectors, axis=1)\n",
    "\n",
    "assert_almost_equal(actual=length_vectors,\n",
    "                    desired=1,\n",
    "                    decimal=5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "kuWUyD8MC3u7"
   },
   "source": [
    "## 3.2 - Mesuring Distance between Words"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Mesure of Similiarty: [Cosine Similariy](https://en.wikipedia.org/wiki/Cosine_similarity)\n",
    "- Measures the cosine of the angle between two vecotrs.\n",
    "- Ranges between 1 (same vector) to -1 (opposite/antipode vector)\n",
    "- In Python, for normalized vectors (Numpy's array), use the `@`(at) operator"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "GdXNWnCRC3u8"
   },
   "outputs": [],
   "source": [
    "w2v_small['cat'] @ w2v_small['cat']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "lqqZKLNlC3u8"
   },
   "outputs": [],
   "source": [
    "w2v_small['cat'] @ w2v_small['cats']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "u7XLxEr3C3u8"
   },
   "outputs": [],
   "source": [
    "degrees(acos(w2v_small['cat'] @ w2v_small['cats']))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "fgLdUfefC3u8"
   },
   "outputs": [],
   "source": [
    "w2v_small['cat'] @ w2v_small['dog']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "2gVuthONC3u8"
   },
   "outputs": [],
   "source": [
    "degrees(acos(w2v_small['cat'] @ w2v_small['dog']))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "8066mq5iC3u8"
   },
   "outputs": [],
   "source": [
    "w2v_small['cat'] @ w2v_small['cow']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "1axuP3UmC3u9"
   },
   "outputs": [],
   "source": [
    "degrees(acos(w2v_small['cat'] @ w2v_small['cow']))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "1I1d9F1-C3u9"
   },
   "outputs": [],
   "source": [
    "w2v_small['cat'] @ w2v_small['graduated']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "rNWC7LF4C3u9"
   },
   "outputs": [],
   "source": [
    "degrees(acos(w2v_small['cat'] @ w2v_small['graduated']))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "DZ7AGgicC3u9"
   },
   "source": [
    "In general, the use of word embeddings to encode words, as an input for NLP systems*, improves their performance compared to one-hot representation.\n",
    "\n",
    "\\* Sometimes the embedding is learned as part of the NLP system."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "SUJV2eErC3u9"
   },
   "source": [
    "## 3.3 - Visualizing Word Embedding in 2D using T-SNE\n",
    "\n",
    "<small>Source: [Google's Seedbank](https://research.google.com/seedbank/seed/pretrained_word_embeddings)</small>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "lk71tJP_C3u9"
   },
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "# take the most common words in the corpus between 200 and 600\n",
    "words = [word for word in w2v_small.index2word[200:600]]\n",
    "\n",
    "# convert the words to vectors\n",
    "embeddings = [w2v_small[word] for word in words]\n",
    "\n",
    "# perform T-SNE\n",
    "words_embedded = TSNE(n_components=2).fit_transform(np.array(embeddings))\n",
    "\n",
    "# ... and visualize!\n",
    "plt.figure(figsize=(20, 20))\n",
    "for i, label in enumerate(words):\n",
    "    x, y = words_embedded[i, :]\n",
    "    plt.scatter(x, y)\n",
    "    plt.annotate(label, xy=(x, y), xytext=(5, 2), textcoords='offset points',\n",
    "                 ha='right', va='bottom', size=11)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "ZQpxDNE1C3u9"
   },
   "source": [
    "#### Extra: [Tensorflow Embedding Projector](http://projector.tensorflow.org)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "7EJaiKzYC3u9"
   },
   "source": [
    "## 3.4 - Most Similar\n",
    "\n",
    "What are the most simlar words to a given word?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "saL5WQkuC3u-"
   },
   "outputs": [],
   "source": [
    "w2v_small.most_similar('cat')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "6FNLPsbxC3u-"
   },
   "source": [
    "Given a list of words, which one doesn't match?\n",
    "\n",
    "(The word furthest away from the mean of all words.)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "mQ4JrRpIC3u-"
   },
   "outputs": [],
   "source": [
    "w2v_small.doesnt_match('breakfast cereal dinner lunch'.split())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "cEIaww5bC3u-"
   },
   "source": [
    "## 3.5 - Vector Arithmetic"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Image(\"./images/vector-addition.png\", width=\"400\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "<small>Source: [Wikipedia](https://commons.wikimedia.org/wiki/File:Vector_add_scale.svg)</small>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "h9y5YEcdC3u-"
   },
   "outputs": [],
   "source": [
    "# nature + science = ?\n",
    "\n",
    "w2v_small.most_similar(positive=['nature', 'science'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "O9Q-3tQdC3u_"
   },
   "source": [
    "## 3.6 - Vector Analogy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "vTl21bZiC3u_"
   },
   "outputs": [],
   "source": [
    "Image(\"./images/linear-relationships.png\", width=800)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<small>Source: [Tensorflow Documentation](https://www.tensorflow.org/tutorials/representation/word2vec)</small>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We now try to represent the following analogy: \n",
    "\n",
    "*king is to man as ____ is to woman*\n",
    "\n",
    "We can think of this as $\\overrightarrow{king} - \\overrightarrow{man} + \\overrightarrow{woman}$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "GRgutcU5C3u_"
   },
   "outputs": [],
   "source": [
    "w2v_small.most_similar(positive=['king', 'woman'],\n",
    "                       negative=['man'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "nJMNz3cqC3u_"
   },
   "source": [
    "## 3.7 - Think about a direction in word embedding as a relation\n",
    "\n",
    "Remember: direction is not a word vector by itself"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "$\\overrightarrow{big} - \\overrightarrow{small} + \\overrightarrow{smaller}$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "02Rm6_wuC3u_"
   },
   "outputs": [],
   "source": [
    "w2v_small.most_similar(positive=['big', 'smaller'],\n",
    "                       negative=['small'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "PUblfTSiC3u_"
   },
   "source": [
    "Sometimes vector arithmetic does not behave as expect. Notice how close the top two results are in the output that follows.\n",
    "\n",
    "$\\overrightarrow{up} - \\overrightarrow{down} + \\overrightarrow{backward}$\n",
    "\n",
    "(we include backwards in the code, otherwise it will be the top result)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "j95uaEETC3vA"
   },
   "outputs": [],
   "source": [
    "w2v_small.most_similar(positive=['up', 'backward', 'backwards'],\n",
    "                       negative=['down'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "XCnE-hnMC3vA"
   },
   "source": [
    "#### Extra Information\n",
    "\n",
    "Keep in mind the word embedding was generated by learning the co-occurrence of words, so the fact that it *empirically* exhibits \"concept arithmetic\", it doesn't necessarily mean it learned it! In fact, it seems it didn't.\n",
    "See: [king - man + woman is queen; but why? by Piotr Migda≈Ç](https://p.migdal.pl/2017/01/06/king-man-woman-queen-why.html)\n",
    "\n",
    "[Demo - Word Analogies Visualizer by Julia Bazi≈Ñska](https://lamyiowce.github.io/word2viz/)\n",
    "\n",
    "In fact, `w2v_small.most_similar` finds the closest word which *is not one* of the given ones. This is a real methodological issue. Nowadays, it is not a common practice anymore to evaluate word embedding with analogies.\n",
    "\n",
    "You can use [`responsibly.we.most_similar`](https://docs.responsibly.ai/word-embedding-bias.html#responsibly.we.utils.most_similar) for the unrestricted version."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## üê≥ **Questions** üê≥\n",
    "\n",
    "+ What are some of the advantages and disadvantages of the 2-dimensional visualization in **3.3**?\n",
    "\n",
    "<br>\n",
    "\n",
    "+ What makes sense to you about what you see in the 2-dimensional visualization in **3.3** and what doesn't?\n",
    "\n",
    "<br>\n",
    "\n",
    "+ Why did the vector arithmetic in **3.6** appear to work but it did not in the latter part of **3.7**?\n",
    "\n",
    "<br>\n",
    "\n",
    "+ Find the words that are most similar to this relation: *see* is to *eye* as ___ is to *ear*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "### Your code here"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "+ Pick a relation of your own and find words most similar to it. What did you expect to see, and what did you find? (Note that the dictionary used here is limited and you may have to experiment to find words that are included.)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "### Your code here"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "uJx1tKxrC3vA"
   },
   "source": [
    "# Part 4: Gender Bias"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "Remember that Word2Vec is primarily trained on Google News.\n",
    "\n",
    "Bolukbasi Tolga, Kai-Wei Chang, James Y. Zou, Venkatesh Saligrama, and Adam T. Kalai. [Man is to computer programmer as woman is to homemaker? debiasing word embeddings](https://arxiv.org/abs/1607.06520). NIPS 2016."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "P8T1Vu6mC3vA"
   },
   "outputs": [],
   "source": [
    "from responsibly.we import load_w2v_small\n",
    "\n",
    "w2v_small = load_w2v_small()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "OkxadIKoC3vC"
   },
   "source": [
    "The method of generating analogies can enforce producing gender sterotyping ones -\n",
    "\n",
    "Nissim, M., van Noord, R., van der Goot, R. (2019). [Fair is Better than Sensational: Man is to Doctor as Woman is to Doctor](https://arxiv.org/abs/1905.09866).\n",
    "\n",
    "... and a [Twitter thread](https://twitter.com/adamfungi/status/1133865428663635968) between the authors of the two papers."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "KDLn6n64C3vC"
   },
   "source": [
    "## 4.1 - What can we take from analogies?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Can we describe some sort of \"gender direction\"?\n",
    "\n",
    "$\\overrightarrow{she} - \\overrightarrow{he}$\n",
    "\n",
    "Notice the order - words in the \"she\" direction will be positive, while words in the \"he\" direction will be negative."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "6Fl65I1vC3vC"
   },
   "outputs": [],
   "source": [
    "gender_direction = w2v_small['she'] - w2v_small['he']\n",
    "\n",
    "gender_direction /= norm(gender_direction)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "j6_SqDfEC3vD"
   },
   "source": [
    "In practice, we calculate the gender direction using multiple definitional pair of words for better estimation (words may have more than one meaning):\n",
    "\n",
    "- woman - man\n",
    "- girl - boy\n",
    "- she - he\n",
    "- mother - father\n",
    "- daughter - son\n",
    "- gal - guy\n",
    "- female - male\n",
    "- her - his\n",
    "- herself - himself\n",
    "- Mary - John"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "9DuWu9yVC3vE"
   },
   "source": [
    "## 4.2 - Projections"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "-6uAKJvTC3vC"
   },
   "outputs": [],
   "source": [
    "gender_direction @ w2v_small['architect']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "55MCmDhWC3vC"
   },
   "outputs": [],
   "source": [
    "gender_direction @ w2v_small['interior_designer']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "KXoDjjFSC3vD"
   },
   "source": [
    "The word *architect* appears in more contexts with *he* than with *she*, and vice versa for *interior designer*."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "ucDbQ13uC3vE"
   },
   "outputs": [],
   "source": [
    "w2v_small_gender_bias = GenderBiasWE(w2v_small, only_lower=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "wOy5EDmRC3vE"
   },
   "outputs": [],
   "source": [
    "w2v_small_gender_bias.positive_end, w2v_small_gender_bias.negative_end"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "NzlmJWFdC3vE"
   },
   "outputs": [],
   "source": [
    "# gender direction\n",
    "w2v_small_gender_bias.direction[:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "KI8U2QhCC3vE"
   },
   "outputs": [],
   "source": [
    "from responsibly.we.data import BOLUKBASI_DATA\n",
    "\n",
    "neutral_profession_names = BOLUKBASI_DATA['gender']['neutral_profession_names']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "tAHD1RdXC3vF"
   },
   "outputs": [],
   "source": [
    "neutral_profession_names[:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "fLgkcOuGC3vF"
   },
   "outputs": [],
   "source": [
    "len(neutral_profession_names)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "qby3XDrfC3vF"
   },
   "outputs": [],
   "source": [
    "# this is the same as using the @ operator on the bias direction\n",
    "w2v_small_gender_bias.project_on_direction(neutral_profession_names[0])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "th7UryxdC3vF"
   },
   "source": [
    "**Let's visualize the projections of professions (neutral and specific by the orthography) on the gender direction**\n",
    "\n",
    "Note that we visuzalize the most extreme professions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "juiycs76C3vF"
   },
   "outputs": [],
   "source": [
    "f, ax = plt.subplots(1, figsize=(10, 10))\n",
    "\n",
    "w2v_small_gender_bias.plot_projection_scores(n_extreme=20, ax=ax);"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "K1MgiofyC3vF"
   },
   "source": [
    "**Extra** - Visualizing gender bias with [Word Clouds](http://wordbias.umiacs.umd.edu/)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "1IlRykZjC3vG"
   },
   "source": [
    "## 4.3 - Are the projections of occupation words on the gender direction related to the real world?\n",
    "\n",
    "Let's take the percentage of female in various occupations from the Labor Force Statistics of 2017 Population Survey.\n",
    "\n",
    "Taken from: [https://arxiv.org/abs/1804.06876](https://arxiv.org/abs/1804.06876)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "-xrMYFBXC3vG"
   },
   "outputs": [],
   "source": [
    "from responsibly.we.data import OCCUPATION_FEMALE_PRECENTAGE\n",
    "\n",
    "sorted(OCCUPATION_FEMALE_PRECENTAGE.items(), key=itemgetter(1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "i2j4_uCFC3vG"
   },
   "outputs": [],
   "source": [
    "f, ax = plt.subplots(1, figsize=(10, 8))\n",
    "\n",
    "w2v_small_gender_bias.plot_factual_association(ax=ax);"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Vrfs4qf5C3vG"
   },
   "source": [
    "## 4.4 Word Embeddings Encoding Gender Stereotypes\n",
    "\n",
    "Garg, N., Schiebinger, L., Jurafsky, D., & Zou, J. (2018). [Word embeddings quantify 100 years of gender and ethnic stereotypes](https://www.pnas.org/content/pnas/115/16/E3635.full.pdf). Proceedings of the National Academy of Sciences, 115(16), E3635-E3644."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Image(\"./images/gender-bias-over-decades.png\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<small>Data: Google Books/Corpus of Historical American English (COHA)</small>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "KwZmL19LC3vG"
   },
   "source": [
    "## 4.5 - Direct Bias Measure\n",
    "\n",
    "1. Project each **neutral profession name** on the gender direction\n",
    "2. Calculate the absolute value of each projection\n",
    "3. Average it all"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "MdXFI9EqC3vG"
   },
   "outputs": [],
   "source": [
    "# using responsibly\n",
    "w2v_small_gender_bias.calc_direct_bias()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "MbB7U8IFC3vH"
   },
   "outputs": [],
   "source": [
    "# what responsibly does:\n",
    "neutral_profession_projections = [w2v_small[word] @ w2v_small_gender_bias.direction\n",
    "                                  for word in neutral_profession_names]\n",
    "\n",
    "abs_neutral_profession_projections = [abs(proj) for proj in neutral_profession_projections]\n",
    "\n",
    "sum(abs_neutral_profession_projections) / len(abs_neutral_profession_projections)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Z3CzXF0iC3vH"
   },
   "source": [
    "## 4.6 - Indirect Bias Measure\n",
    "Similarity due to shared \"gender direction\" projection"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "hmHvybUKC3vH"
   },
   "outputs": [],
   "source": [
    "w2v_small_gender_bias.generate_closest_words_indirect_bias('softball',\n",
    "                                                           'football')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## üê≥ **Questions** üê≥"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Building off the example in section **4.2**, calculate three additional projects of the gender direction onto three words of your choice"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "bvnuDrC7C3vD"
   },
   "outputs": [],
   "source": [
    "# Calculate three additional gender projections here"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "- What do you think of the idea of a gender direction as quantified in section **4.1** above?\n",
    "\n",
    "    - What do you think the formula does right?\n",
    "\n",
    "    - What do you think the formula does wrong?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Using the methods shown in **4.1** and **4.2**, define a new direction for a concept of your choice besides gender\n",
    "\n",
    "    - What is your concept?\n",
    "    \n",
    "    - What are your starting and ending words?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Calculate the new concept direction, and project it onto three words of your choice below"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "### Calculate the new direction\n",
    "\n",
    "\n",
    "### Project it onto three words of your choice"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- What do your results tell you?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "x2AxxNoXC3vH"
   },
   "source": [
    "# Part 5: Mitigating Bias\n",
    "\n",
    "> We intentionally do not reference the resulting embeddings as \"debiased\" or free from all gender bias, and\n",
    "prefer the term \"mitigating bias\" rather that \"debiasing,\" to guard against the misconception that the resulting\n",
    "embeddings are entirely \"safe\" and need not be critically evaluated for bias in downstream tasks. <small>James-Sorenson, H., & Alvarez-Melis, D. (2019). [Probabilistic Bias Mitigation in Word Embeddings](https://arxiv.org/pdf/1910.14497.pdf). arXiv preprint arXiv:1910.14497.</small>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "TlW6-I0vECj5"
   },
   "source": [
    "## 5.1 - Neutralize\n",
    "\n",
    "We will remove the gender projection from all the words, except the gender-specific ones, and then normalize.\n",
    "\n",
    "We need to \"learn\" what are the gender-specific words in the vocabulary for a seed set of gender-specific words (we do this by semi-automatic use of [WordNet](https://en.wikipedia.org/wiki/WordNet))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "RzIzwzcXC3vH"
   },
   "outputs": [],
   "source": [
    "w2v_small_gender_debias = w2v_small_gender_bias.debias(method='neutralize', inplace=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "J3hgtHyxC3vH"
   },
   "outputs": [],
   "source": [
    "print('home:',\n",
    "      'before =', w2v_small_gender_bias.model['home'] @ w2v_small_gender_bias.direction,\n",
    "      'after = ', w2v_small_gender_debias.model['home'] @ w2v_small_gender_debias.direction)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "IZC7y2I9C3vI"
   },
   "outputs": [],
   "source": [
    "print('man:',\n",
    "      'before =', w2v_small_gender_bias.model['man'] @ w2v_small_gender_bias.direction,\n",
    "      'after = ', w2v_small_gender_debias.model['man'] @ w2v_small_gender_debias.direction)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "mPh777kyC3vI"
   },
   "outputs": [],
   "source": [
    "print('woman:',\n",
    "      'before =', w2v_small_gender_bias.model['woman'] @ w2v_small_gender_bias.direction,\n",
    "      'after = ', w2v_small_gender_debias.model['woman'] @ w2v_small_gender_debias.direction)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "hFf08ZQmC3vI"
   },
   "outputs": [],
   "source": [
    "w2v_small_gender_debias.calc_direct_bias()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "G3sd0hLUC3vI"
   },
   "outputs": [],
   "source": [
    "f, ax = plt.subplots(1, figsize=(10, 10))\n",
    "\n",
    "w2v_small_gender_debias.plot_projection_scores(n_extreme=20, ax=ax);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "aMChX6EtC3vI"
   },
   "outputs": [],
   "source": [
    "f, ax = plt.subplots(1, figsize=(10, 8))\n",
    "\n",
    "w2v_small_gender_debias.plot_factual_association(ax=ax);"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "MKh54qxZC3vI"
   },
   "source": [
    "## 5.2 Equalize"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "ulo550zHC3vJ"
   },
   "outputs": [],
   "source": [
    "w2v_small_gender_debias.model['grandfather'] @ w2v_small_gender_debias.model['babysitter']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "W_bY_M7_C3vJ"
   },
   "outputs": [],
   "source": [
    "w2v_small_gender_debias.model['grandmother'] @ w2v_small_gender_debias.model['babysitter']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Notice that the projection of \"grandfather\" and \"grandmother\" onto the now neutral word \"babysitter\" are not equal, even though we have \"debiased\" our embedding. We might prefer that in a \"debiased\" embedding, \"grandfather\" and \"grandmother\" have roughly the same projection onto neutral words. Below you can see an example of some of the pairs we are interested in equalizing."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "2BcJxNYWC3vJ"
   },
   "outputs": [],
   "source": [
    "BOLUKBASI_DATA['gender']['equalize_pairs'][:10]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "jZrAc0y-C3vJ"
   },
   "source": [
    "## 5.3 Hard Debias = Neutralize + Equalize"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now we debias by both neutralizing as we did before along with equalizing across the pairs we indentified above (note that the list that was printed out is not exhaustive)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "gB5VkrfeC3vJ"
   },
   "outputs": [],
   "source": [
    "w2v_small_gender_debias = w2v_small_gender_bias.debias(method='hard', inplace=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "R4UL6HBOC3vJ"
   },
   "outputs": [],
   "source": [
    "print('home:',\n",
    "      'before =', w2v_small_gender_bias.model['home'] @ w2v_small_gender_bias.direction,\n",
    "      'after = ', w2v_small_gender_debias.model['home'] @ w2v_small_gender_debias.direction)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "LnTmE2L5C3vJ"
   },
   "outputs": [],
   "source": [
    "print('man:',\n",
    "      'before =', w2v_small_gender_bias.model['man'] @ w2v_small_gender_bias.direction,\n",
    "      'after = ', w2v_small_gender_debias.model['man'] @ w2v_small_gender_debias.direction)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "zD8SJLt3C3vJ"
   },
   "outputs": [],
   "source": [
    "print('woman:',\n",
    "      'before =', w2v_small_gender_bias.model['woman'] @ w2v_small_gender_bias.direction,\n",
    "      'after = ', w2v_small_gender_debias.model['woman'] @ w2v_small_gender_debias.direction)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "8ZVur5jOC3vK"
   },
   "outputs": [],
   "source": [
    "w2v_small_gender_debias.calc_direct_bias()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "IPslsCZJC3vK"
   },
   "outputs": [],
   "source": [
    "w2v_small_gender_debias.model['grandfather'] @ w2v_small_gender_debias.model['babysitter']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "0uqdHLMDC3vK"
   },
   "outputs": [],
   "source": [
    "w2v_small_gender_debias.model['grandmother'] @ w2v_small_gender_debias.model['babysitter']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Notice that \"grandfather\" and \"grandmother\" now have (almost exactly) the same projection onto \"babysitter\"."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "ZGLeaGqLC3vK"
   },
   "outputs": [],
   "source": [
    "f, ax = plt.subplots(1, figsize=(10, 10))\n",
    "\n",
    "w2v_small_gender_debias.plot_projection_scores(n_extreme=20, ax=ax);"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The disadvantage of equalization is that it might remove meaningful associations, such as the verb meaning of \"grandfather\", e.g. \"to grandfather a regulation\". Equalization removes this distinction."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "FEBDBsB-C3vK"
   },
   "source": [
    "## 5.4 - Compare Preformances\n",
    "\n",
    "After debiasing, the performance of the word embedding (using standard benchmarks) only gets slightly worse!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "iFNefinzC3vK"
   },
   "outputs": [],
   "source": [
    "w2v_small_gender_bias.evaluate_word_embedding()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "8pnxA6vzC3vK"
   },
   "outputs": [],
   "source": [
    "w2v_small_gender_debias.evaluate_word_embedding()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## üê≥ **Questions** üê≥"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- What is \"neutralizing\", and what is \"equalizing\" in the context of \"hard debiasing\", and how do they differ? \n",
    "    \n",
    "    <small>You may find it helpful to look at the following paper from class (you may copy the definitions from the paper, but the explanation on how they differ should be your own):</small>\n",
    "    <small>[Man is to Computer Programmer as Woman is to Homemaker? Debiasing Word Embeddings](https://arxiv.org/pdf/1607.06520.pdf)</small>\n",
    "\n",
    "    "
   ]
  }
 ],
 "metadata": {
  "colab": {
   "collapsed_sections": [],
   "name": "tutorial-bias-word-embedding.ipynb",
   "provenance": [],
   "toc_visible": true
  },
  "interpreter": {
   "hash": "24767a0643266da2a20fc528f6cd894b6d6b2f3ac2f4a851d70b18cf4346ddf3"
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
